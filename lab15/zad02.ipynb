{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithm with gym library\n",
    "### In this experiment, we will try to do genetic algorithm for games: Lunar Lander and Frozen Lake. The first one is about landing with a rocket on moon using 3 engines. The second game is like a labyrinth. To do it we will use Pygad library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pygad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func(solution, solution_idx):\n",
    "    total_reward = 0\n",
    "    # Resetowanie gry\n",
    "    state = env.reset(seed=42)\n",
    "\n",
    "    for action in solution:\n",
    "        state, reward, done, info , _ = env.step(action.astype(int))\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie środowiska gry\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# Definicja problemu optymalizacyjnego dla algorytmu genetycznego\n",
    "gene_space = [0, 1, 2, 3]\n",
    "num_genes = 100\n",
    "num_generations = 100\n",
    "num_parents_mating = 50\n",
    "sol_per_pop = 500\n",
    "keep_parents = 10\n",
    "parent_selection_type = \"sss\"\n",
    "crossover_type = \"single_point\"\n",
    "mutation_type = \"random\"\n",
    "mutation_percent_genes = 10\n",
    "\n",
    "# Tworzenie instancji algorytmu genetycznego\n",
    "ga_instance = pygad.GA(gene_space=gene_space,\n",
    "                       num_genes=num_genes,\n",
    "                       num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       fitness_func=fitness_func,\n",
    "                       stop_criteria=\"reach_105\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze rozwiązanie: [0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 3. 0. 0. 3. 1. 1. 3. 2. 0. 1. 2. 0. 1. 0.\n",
      " 3. 2. 3. 1. 1. 0. 3. 1. 1. 0. 2. 2. 3. 0. 2. 1. 0. 2. 0. 0. 0. 1. 0. 0.\n",
      " 3. 0. 3. 1. 3. 2. 2. 3. 3. 3. 3. 0. 2. 1. 0. 3. 2. 1. 1. 1. 1. 2. 3. 1.\n",
      " 0. 1. 2. 3. 3. 3. 3. 1. 1. 1. 3. 1. 1. 2. 1. 3. 0. 1. 2. 0. 2. 1. 1. 3.\n",
      " 3. 2. 2. 3.]\n",
      "Wynik optymalizacji: 116.58772144660429\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# Rozpoczęcie optymalizacji\n",
    "ga_instance.run()\n",
    "\n",
    "# Optymalne rozwiązanie\n",
    "best_solution, solution, solution_fitness= ga_instance.best_solution()\n",
    "\n",
    "# Wydrukowanie wyników\n",
    "print(\"Najlepsze rozwiązanie:\", best_solution)\n",
    "print(\"Wynik optymalizacji:\", solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "0.0 (<class 'numpy.float64'>) invalid ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done \u001b[39mand\u001b[39;00m num_steps \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(best_solution):\n\u001b[0;32m      9\u001b[0m     action \u001b[39m=\u001b[39m best_solution[num_steps]\n\u001b[1;32m---> 10\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(action)\n\u001b[0;32m     12\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\olewn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\olewn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\olewn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\env_checker.py:37\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchecked_step \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchecked_step \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\olewn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:214\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m result \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m    215\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    216\u001b[0m     result, \u001b[39mtuple\u001b[39m\n\u001b[0;32m    217\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpects step result to be a tuple, actual type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(result)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(result) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\olewn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py:482\u001b[0m, in \u001b[0;36mLunarLander.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    480\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(action, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m    481\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mcontains(\n\u001b[0;32m    483\u001b[0m         action\n\u001b[0;32m    484\u001b[0m     ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00maction\u001b[39m!r}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(action)\u001b[39m}\u001b[39;00m\u001b[39m) invalid \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m \u001b[39m# Engines\u001b[39;00m\n\u001b[0;32m    487\u001b[0m tip \u001b[39m=\u001b[39m (math\u001b[39m.\u001b[39msin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlander\u001b[39m.\u001b[39mangle), math\u001b[39m.\u001b[39mcos(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlander\u001b[39m.\u001b[39mangle))\n",
      "\u001b[1;31mAssertionError\u001b[0m: 0.0 (<class 'numpy.float64'>) invalid "
     ]
    }
   ],
   "source": [
    "# replay the game\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "\n",
    "state = env.reset(seed=42)\n",
    "done = False\n",
    "num_steps = 0\n",
    "\n",
    "while not done and num_steps < len(best_solution):\n",
    "    action = best_solution[num_steps]\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    # print(action)\n",
    "    env.render()\n",
    "\n",
    "    num_steps += 1\n",
    "    if terminated or truncated:\n",
    "      env.close()\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
